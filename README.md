# Freestyle Events Calendar Scraper

Un proyecto de web scraping desarrollado por **Sergie Code** que extrae eventos de freestyle de mÃºltiples fuentes y los muestra en una interfaz web moderna con calendario interactivo.

## ğŸ¯ CaracterÃ­sticas

- **Scraping automatizado** de eventos de freestyle de mÃºltiples fuentes:
  - Red Bull Batalla
  - Urban Roosters (FMS)
  - God Level
  - SupremacÃ­a MC
  - Ticketmaster y Passline
- **Base de datos SQLite** con persistencia de datos
- **Interfaz web moderna** con Bootstrap 5 y JavaScript
- **API REST completa** para acceso a los datos
- **Filtros dinÃ¡micos** por paÃ­s, organizador y fecha
- **Calendario visual** de eventos con vista de tarjetas
- **Suite de pruebas completa** con 30 tests automatizados
- **Compatible con Windows/VSCode/PowerShell**
- **Sistema de estadÃ­sticas** de eventos

## ğŸ› ï¸ TecnologÃ­as

- **Python 3.8+**
- **Flask** (Backend web)
- **BeautifulSoup + Selenium** (Web scraping)
- **Pandas** (ManipulaciÃ³n de datos)
- **SQLite** (Base de datos)
- **Bootstrap 5** (Frontend responsivo)
- **JavaScript ES6** (Interactividad)
- **Pytest** (Testing framework)

## ğŸ“‹ InstalaciÃ³n y ConfiguraciÃ³n

### Requisitos Previos
- Python 3.8 o superior
- Git
- Google Chrome (para Selenium)

### Pasos de InstalaciÃ³n

1. **Clona el repositorio:**
```powershell
git clone https://github.com/sergiecode/python-web-scrapping-freestyle-events-calendar.git
cd python-web-scrapping-freestyle-events-calendar
```

2. **Crea y activa un entorno virtual:**
```powershell
python -m venv venv
venv\Scripts\Activate.ps1
```

3. **Instala las dependencias:**
```powershell
pip install -r requirements.txt
```

4. **Ejecuta el scraper inicial para poblar la base de datos:**
```powershell
python scraper/run_all.py
```

5. **Inicia la aplicaciÃ³n web:**
```powershell
python webapp/app.py
```

6. **Abre tu navegador en:** `http://localhost:5000`

## âœ… Testing

El proyecto incluye una suite completa de 30 pruebas automatizadas:

### Ejecutar todas las pruebas:
```powershell
pytest tests/ -v
```

### Ejecutar pruebas especÃ­ficas:
```powershell
# Pruebas de utilidades
pytest tests/test_utils.py -v

# Pruebas de scrapers
pytest tests/test_scrapers.py -v

# Pruebas de integraciÃ³n
pytest tests/test_integration.py -v

# Pruebas de la webapp
pytest tests/test_webapp.py -v
```

### Script de prueba para Windows/PowerShell:
```powershell
# Ejecutar con el script incluido
.\run_tests.ps1
```

5. **Inicia la aplicaciÃ³n web:**
```powershell
python webapp/app.py
```

6. **Abre tu navegador en:** `http://localhost:5000`

## ğŸ“ Estructura del Proyecto

```
python-web-scrapping-freestyle-events-calendar/
â”œâ”€â”€ scraper/                    # MÃ³dulos de web scraping
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ redbull.py             # Scraper de Red Bull Batalla
â”‚   â”œâ”€â”€ fms.py                 # Scraper de Urban Roosters (FMS)
â”‚   â”œâ”€â”€ godlevel.py            # Scraper de God Level
â”‚   â”œâ”€â”€ supremacia.py          # Scraper de SupremacÃ­a MC
â”‚   â”œâ”€â”€ tickets.py             # Scraper de sitios de tickets
â”‚   â”œâ”€â”€ utils.py               # Utilidades y funciones comunes
â”‚   â””â”€â”€ run_all.py             # Script principal de scraping
â”œâ”€â”€ webapp/                     # AplicaciÃ³n web Flask
â”‚   â”œâ”€â”€ app.py                 # Servidor Flask con API REST
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â”œâ”€â”€ index.html         # Interfaz principal (Bootstrap 5)
â”‚   â”‚   â””â”€â”€ api_test.html      # PÃ¡gina de prueba de API
â”‚   â””â”€â”€ static/
â”‚       â””â”€â”€ styles.css         # Estilos CSS personalizados
â”œâ”€â”€ tests/                      # Suite de pruebas (30 tests)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_utils.py          # Pruebas de utilidades
â”‚   â”œâ”€â”€ test_scrapers.py       # Pruebas de scrapers
â”‚   â”œâ”€â”€ test_integration.py    # Pruebas de integraciÃ³n
â”‚   â””â”€â”€ test_webapp.py         # Pruebas de la webapp
â”œâ”€â”€ data/                       # Datos y base de datos
â”‚   â”œâ”€â”€ eventos.csv            # ExportaciÃ³n en CSV
â”‚   â””â”€â”€ eventos.db             # Base de datos SQLite
â”œâ”€â”€ requirements.txt            # Dependencias de Python
â”œâ”€â”€ run_tests.ps1              # Script de pruebas para PowerShell
â”œâ”€â”€ debug_api.py               # Script de debug de API
â”œâ”€â”€ README.md                  # Este archivo
â””â”€â”€ .gitignore                 # Archivos ignorados por Git
```

## ğŸš€ Uso de la AplicaciÃ³n

### ğŸŒ Interfaz Web

La aplicaciÃ³n web ofrece una interfaz moderna y responsiva:

- **PÃ¡gina principal** (`http://localhost:5000`): Vista de tarjetas con todos los eventos
- **Filtros dinÃ¡micos**: Por paÃ­s, organizador y rango de fechas
- **BÃºsqueda en tiempo real**: Busca eventos por nombre o descripciÃ³n
- **Vista de estadÃ­sticas**: Contador de eventos y distribuciÃ³n por organizador
- **DiseÃ±o responsivo**: Compatible con mÃ³viles y tablets

### ğŸ”§ Scraping Manual

```powershell
# Ejecutar todos los scrapers
python scraper/run_all.py

# Ejecutar scraper especÃ­fico
python scraper/redbull.py
python scraper/fms.py
python scraper/godlevel.py
python scraper/supremacia.py
python scraper/tickets.py
```

### ğŸ“¡ API REST Endpoints

| Endpoint | MÃ©todo | DescripciÃ³n | ParÃ¡metros |
|----------|--------|-------------|------------|
| `/` | GET | PÃ¡gina principal | - |
| `/api/eventos` | GET | Todos los eventos | `pais`, `organizador` |
| `/api/stats` | GET | EstadÃ­sticas de eventos | - |
| `/test` | GET | PÃ¡gina de prueba de API | - |

#### Ejemplos de uso de la API:

```bash
# Todos los eventos
curl http://localhost:5000/api/eventos

# Filtrar por paÃ­s
curl "http://localhost:5000/api/eventos?pais=EspaÃ±a"

# Filtrar por organizador
curl "http://localhost:5000/api/eventos?organizador=Red Bull"

# MÃºltiples filtros
curl "http://localhost:5000/api/eventos?pais=Argentina&organizador=Urban Roosters"

# EstadÃ­sticas
curl http://localhost:5000/api/stats
```

### ğŸ›ï¸ Filtros Disponibles

- **Por paÃ­s**: EspaÃ±a, MÃ©xico, Argentina, Colombia, Chile, PerÃº, etc.
- **Por organizador**: Red Bull, Urban Roosters, God Level, SupremacÃ­a MC
- **Por fecha**: Eventos prÃ³ximos, eventos pasados, rango personalizado
- **BÃºsqueda**: Por nombre del evento o descripciÃ³n

### ğŸ” Debug y Mantenimiento

```powershell
# Verificar funcionamiento de la API
python debug_api.py

# Limpiar y recrear la base de datos
python scraper/utils.py

# Ver logs de la aplicaciÃ³n web
python webapp/app.py  # Los logs aparecen en la consola
```

## ğŸ“Š Datos ExtraÃ­dos

Para cada evento se extrae la siguiente informaciÃ³n:

| Campo | DescripciÃ³n | Ejemplo |
|-------|-------------|---------|
| **nombre** | Nombre del evento | "Red Bull Batalla Nacional EspaÃ±a" |
| **fecha** | Fecha del evento | "2024-03-15" |
| **hora** | Hora del evento | "20:00" |
| **ciudad** | Ciudad donde se realiza | "Madrid" |
| **pais** | PaÃ­s del evento | "EspaÃ±a" |
| **venue** | Lugar especÃ­fico | "Palacio de Deportes" |
| **organizador** | Organizador del evento | "Red Bull" |
| **link** | URL oficial | "https://..." |
| **descripcion** | DescripciÃ³n del evento | "Batalla nacional de freestyle" |

### ğŸ“ˆ EstadÃ­sticas Disponibles

La API de estadÃ­sticas (`/api/stats`) proporciona:
- **Total de eventos** en la base de datos
- **Eventos por organizador** (distribuciÃ³n)
- **Eventos por paÃ­s** (distribuciÃ³n)
- **Eventos prÃ³ximos** (prÃ³ximos 30 dÃ­as)
- **Ãšltima actualizaciÃ³n** de la base de datos

## ğŸ”„ AutomatizaciÃ³n y ProgramaciÃ³n

### ConfiguraciÃ³n de Scraping AutomÃ¡tico

```python
# Ejemplo de automatizaciÃ³n con schedule
import schedule
import time
from scraper.run_all import main as run_scrapers

def job():
    print("Ejecutando scraping automÃ¡tico...")
    run_scrapers()
    print("Scraping completado.")

# Ejecutar cada 6 horas
schedule.every(6).hours.do(job)

# Ejecutar diariamente a las 9:00 AM
schedule.every().day.at("09:00").do(job)

while True:
    schedule.run_pending()
    time.sleep(1)
```

### ConfiguraciÃ³n con Windows Task Scheduler

1. Abre el **Programador de tareas** de Windows
2. Crea una **Nueva tarea bÃ¡sica**
3. Configura el **Desencadenador** (ej: diario)
4. En **AcciÃ³n**, selecciona "Iniciar un programa"
5. **Programa**: `C:\ruta\a\python.exe`
6. **Argumentos**: `C:\ruta\al\proyecto\scraper\run_all.py`
7. **Iniciar en**: `C:\ruta\al\proyecto\`

## ğŸ› ï¸ Desarrollo y PersonalizaciÃ³n

### Agregar un Nuevo Scraper

1. Crea un nuevo archivo en `scraper/nuevo_sitio.py`:

```python
import requests
from bs4 import BeautifulSoup
from .utils import EventsAPI, limpiar_texto

def scraper_nuevo_sitio():
    """Scraper para un nuevo sitio de eventos"""
    api = EventsAPI()
    
    # Tu lÃ³gica de scraping aquÃ­
    url = "https://nuevo-sitio.com/eventos"
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')
    
    # Extraer eventos
    eventos = []
    for evento_elem in soup.find_all('div', class_='evento'):
        evento = {
            'nombre': limpiar_texto(evento_elem.find('h2').text),
            'fecha': evento_elem.find('time').get('datetime'),
            # ... mÃ¡s campos
        }
        eventos.append(evento)
    
    # Guardar en la base de datos
    for evento in eventos:
        api.agregar_evento(**evento)
    
    return len(eventos)

if __name__ == "__main__":
    count = scraper_nuevo_sitio()
    print(f"Scraped {count} eventos from Nuevo Sitio")
```

2. Agrega el import en `scraper/run_all.py`:

```python
from .nuevo_sitio import scraper_nuevo_sitio

def main():
    # ... otros scrapers
    count += scraper_nuevo_sitio()
```

### Personalizar la Interfaz Web

Los archivos principales para personalizaciÃ³n:

- **`webapp/templates/index.html`**: Estructura HTML y JavaScript
- **`webapp/static/styles.css`**: Estilos CSS personalizados
- **`webapp/app.py`**: LÃ³gica del servidor y API

## ğŸ› SoluciÃ³n de Problemas

### Problemas Comunes

#### La pÃ¡gina web no muestra eventos
```powershell
# 1. Verificar que hay eventos en la base de datos
python debug_api.py

# 2. Limpiar cachÃ© del navegador (Ctrl + F5)

# 3. Verificar que el servidor estÃ¡ corriendo
curl http://localhost:5000/api/eventos
```

#### Error de ChromeDriver
```powershell
# Instalar/actualizar ChromeDriver
# Descargar desde: https://chromedriver.chromium.org/
# Colocar en PATH o en la carpeta del proyecto
```

#### Error de mÃ³dulos no encontrados
```powershell
# Asegurarse de que el entorno virtual estÃ¡ activado
venv\Scripts\Activate.ps1

# Reinstalar dependencias
pip install -r requirements.txt
```

#### Pruebas fallan
```powershell
# Ejecutar pruebas individuales para identificar el problema
pytest tests/test_utils.py -v
pytest tests/test_scrapers.py -v

# Verificar entorno de pruebas
python -m pytest --version
```

### Logs y Debug

Para activar logs detallados:

```python
# En webapp/app.py
import logging
logging.basicConfig(level=logging.DEBUG)
```

### Compatibilidad

- **Sistema Operativo**: Windows 10/11, Linux, macOS
- **Python**: 3.8, 3.9, 3.10, 3.11
- **Navegadores**: Chrome, Firefox, Edge, Safari
- **Terminal**: PowerShell, CMD, Git Bash

## ğŸ“ Changelog

### v2.0.0 (Actual)
- âœ… Suite completa de 30 pruebas automatizadas
- âœ… Interfaz web moderna con Bootstrap 5
- âœ… API REST completa con filtros avanzados
- âœ… Sistema de estadÃ­sticas de eventos
- âœ… Compatibilidad completa con Windows/PowerShell
- âœ… PÃ¡gina de debug y pruebas de API
- âœ… DocumentaciÃ³n completa actualizada

### v1.0.0 (Anterior)
- Scraping bÃ¡sico de mÃºltiples fuentes
- Base de datos SQLite simple
- Interfaz web bÃ¡sica
- API REST bÃ¡sica

## ğŸ¤ Contribuir

Â¿Quieres agregar mÃ¡s fuentes de eventos o mejorar el proyecto? Â¡Las contribuciones son bienvenidas!

### Proceso de ContribuciÃ³n:

1. **Fork** el proyecto
2. Crea una **rama** para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. **Commit** tus cambios (`git commit -am 'Agrega nueva funcionalidad'`)
4. **Push** a la rama (`git push origin feature/nueva-funcionalidad`)
5. Abre un **Pull Request**

### GuÃ­as para Contribuir:

- MantÃ©n el cÃ³digo limpio y bien documentado
- Agrega pruebas para nuevas funcionalidades
- Sigue las convenciones de naming existentes
- Actualiza la documentaciÃ³n segÃºn sea necesario
- Prueba en Windows/PowerShell antes de enviar PR

### Ideas para Contribuir:

- Nuevos scrapers de sitios de eventos
- Mejoras en la interfaz web
- Optimizaciones de rendimiento
- IntegraciÃ³n con APIs externas
- Notificaciones de eventos
- Export a diferentes formatos (JSON, XML, iCal)

## ï¿½ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.

## ï¿½ğŸ“º Sobre el Autor

**Sergie Code** - Software Engineer y educador de programaciÃ³n en YouTube.

### ğŸŒ SÃ­gueme en mis redes:

- ğŸ“¸ **Instagram**: https://www.instagram.com/sergiecode
- ğŸ§‘ğŸ¼â€ğŸ’» **LinkedIn**: https://www.linkedin.com/in/sergiecode/
- ğŸ“½ï¸ **YouTube**: https://www.youtube.com/@SergieCode
- ğŸ˜º **GitHub**: https://github.com/sergiecode
- ğŸ‘¤ **Facebook**: https://www.facebook.com/sergiecodeok
- ğŸï¸ **TikTok**: https://www.tiktok.com/@sergiecode
- ğŸ•Šï¸ **Twitter**: https://twitter.com/sergiecode
- ğŸ§µ **Threads**: https://www.threads.net/@sergiecode

### ğŸ’¡ Otros Proyectos

Visita mi GitHub para mÃ¡s proyectos educativos de programaciÃ³n y desarrollo web.

## âš ï¸ Disclaimer

Este proyecto es **solo para fines educativos**. 

**Importante**:
- Respeta los **tÃ©rminos de servicio** de las pÃ¡ginas web que scrapeas
- Implementa **delays apropiados** entre requests para no sobrecargar los servidores
- Considera el **uso Ã©tico** del web scraping
- **No uses** este cÃ³digo para fines comerciales sin permisos apropiados
- **Verifica** la legalidad del scraping en tu jurisdicciÃ³n

---

## ğŸŒŸ Â¡Apoya el Proyecto!

Si este proyecto te ha sido Ãºtil:
- â­ **Dale una estrella** en GitHub
- ğŸ› **Reporta bugs** o sugiere mejoras
- ğŸ¤ **Contribuye** con cÃ³digo o documentaciÃ³n
- ğŸ“¢ **Comparte** el proyecto en tus redes

Â¡Gracias por usar Freestyle Events Calendar Scraper! ğŸ¤ğŸ”¥
